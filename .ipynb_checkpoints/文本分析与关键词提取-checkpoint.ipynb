{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概念：\n",
    "\n",
    "词频（Term Frequency）：指的是某一指定的词在该文档中出现的次数。 逆文档频率（Inverse Document\n",
    "Frequency）：IDF就是每个词的权重，它的大小与一个词的常见程度成反比。\n",
    "TF-IDF：衡量某个词是否关键词的指标，该值越大，是关键词的可能性就越大。\n",
    "计算公式：\n",
    "TF（词频）=该词在文档中出现的频率=该词在文章中出现的次数/该文章的总词数。\n",
    "IDF（逆文档频率）=log(文档总数/（包含该词的文档数+1））\n",
    "TF-IDF=TF*IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据源：http://www.sogou.com/labs/resource/cs.php\n",
    "视频教程:https://www.bilibili.com/video/BV1gt41147P6?p=3\n",
    "文字教程：https://blog.csdn.net/qq_39494028/article/details/83047485"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3812, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel('d.xlsx',encoding='utf-8')\n",
    "df=pd.DataFrame(data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "来源:华奥搜狐 作者:白斯特 中国女足完美的在最后时刻绝杀世界明星联队,今天全世界的球迷为中国喝彩。然而打入世界明星联队第一球的德国人波勒斯不以为然,她表示:“如果中国队在世界杯上遇到德国队,赢球的肯定是我们。” 北京时间4月21日晚,中国女足与世界明星联队的比赛在武汉体育中心结束。 最终,凭借最后时刻的进球,中国队以3比2击败来访的世界明星联队。无论是明星联主帅还是核心球员都称赞中国队在本场比赛的表现。然而打入明星联队第一球的德国人波勒斯却满不在乎。她说:“我并不觉得输掉本场比赛有什么遗憾。这就是一场表演赛,我们都感到很激动。如果在世界杯上中国队遇到德国队,那我们肯定会取得比赛胜利。” 比赛结束后,同样来自德国的主教练蒂纳与波勒斯的态度截然相反,蒂纳的沮丧让人们看到了她对本场比赛的重视,而波勒斯则信誓旦旦,放出话来,德国将是世界第一。曾经0比8惨败给德国后,中国女足进入了一个变革时期。中国女足再也不是世界的霸主,甚至在亚洲也难保第一。一连串的溃败也让世界强队把中国队排出在竞争对手之列。 波勒斯的叫板也就显得自然,中国女足能否通过本场比赛重拾信心,世界杯前还有很多路要走。 (责任编辑:liumiaoyao) Copyright c 2007 Sohu.com Inc. All rights reserved. 搜狐公司 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "content=df.content.values.tolist()#转换为列表\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_s=[]\n",
    "for line in content:\n",
    "    current_segment=jieba.lcut(line)\n",
    "    if len(current_segment)>1 and current_segment!='\\r\\n':#换行符\n",
    "        content_s.append(current_segment)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '来源',\n",
       " ':',\n",
       " '华奥',\n",
       " '搜狐',\n",
       " ' ',\n",
       " '作者',\n",
       " ':',\n",
       " '白',\n",
       " '斯特',\n",
       " ' ',\n",
       " '中国女足',\n",
       " '完美',\n",
       " '的',\n",
       " '在',\n",
       " '最后',\n",
       " '时刻',\n",
       " '绝杀',\n",
       " '世界',\n",
       " '明星',\n",
       " '联队',\n",
       " ',',\n",
       " '今天',\n",
       " '全世界',\n",
       " '的',\n",
       " '球迷',\n",
       " '为',\n",
       " '中国',\n",
       " '喝彩',\n",
       " '。',\n",
       " '然而',\n",
       " '打入',\n",
       " '世界',\n",
       " '明星',\n",
       " '联队',\n",
       " '第一',\n",
       " '球',\n",
       " '的',\n",
       " '德国人',\n",
       " '波',\n",
       " '勒斯',\n",
       " '不以为然',\n",
       " ',',\n",
       " '她',\n",
       " '表示',\n",
       " ':',\n",
       " '“',\n",
       " '如果',\n",
       " '中国队',\n",
       " '在',\n",
       " '世界杯',\n",
       " '上',\n",
       " '遇到',\n",
       " '德国队',\n",
       " ',',\n",
       " '赢球',\n",
       " '的',\n",
       " '肯定',\n",
       " '是',\n",
       " '我们',\n",
       " '。',\n",
       " '”',\n",
       " ' ',\n",
       " '北京',\n",
       " '时间',\n",
       " '4',\n",
       " '月',\n",
       " '21',\n",
       " '日晚',\n",
       " ',',\n",
       " '中国女足',\n",
       " '与',\n",
       " '世界',\n",
       " '明星',\n",
       " '联队',\n",
       " '的',\n",
       " '比赛',\n",
       " '在',\n",
       " '武汉',\n",
       " '体育中心',\n",
       " '结束',\n",
       " '。',\n",
       " ' ',\n",
       " '最终',\n",
       " ',',\n",
       " '凭借',\n",
       " '最后',\n",
       " '时刻',\n",
       " '的',\n",
       " '进球',\n",
       " ',',\n",
       " '中国队',\n",
       " '以',\n",
       " '3',\n",
       " '比',\n",
       " '2',\n",
       " '击败',\n",
       " '来访',\n",
       " '的',\n",
       " '世界',\n",
       " '明星',\n",
       " '联队',\n",
       " '。',\n",
       " '无论是',\n",
       " '明星',\n",
       " '联',\n",
       " '主帅',\n",
       " '还是',\n",
       " '核心',\n",
       " '球员',\n",
       " '都',\n",
       " '称赞',\n",
       " '中国队',\n",
       " '在',\n",
       " '本场',\n",
       " '比赛',\n",
       " '的',\n",
       " '表现',\n",
       " '。',\n",
       " '然而',\n",
       " '打入',\n",
       " '明星',\n",
       " '联队',\n",
       " '第一',\n",
       " '球',\n",
       " '的',\n",
       " '德国人',\n",
       " '波',\n",
       " '勒斯',\n",
       " '却',\n",
       " '满不在乎',\n",
       " '。',\n",
       " '她',\n",
       " '说',\n",
       " ':',\n",
       " '“',\n",
       " '我',\n",
       " '并',\n",
       " '不',\n",
       " '觉得',\n",
       " '输掉',\n",
       " '本场',\n",
       " '比赛',\n",
       " '有',\n",
       " '什么',\n",
       " '遗憾',\n",
       " '。',\n",
       " '这',\n",
       " '就是',\n",
       " '一场',\n",
       " '表演赛',\n",
       " ',',\n",
       " '我们',\n",
       " '都',\n",
       " '感到',\n",
       " '很',\n",
       " '激动',\n",
       " '。',\n",
       " '如果',\n",
       " '在',\n",
       " '世界杯',\n",
       " '上',\n",
       " '中国队',\n",
       " '遇到',\n",
       " '德国队',\n",
       " ',',\n",
       " '那',\n",
       " '我们',\n",
       " '肯定',\n",
       " '会',\n",
       " '取得',\n",
       " '比赛',\n",
       " '胜利',\n",
       " '。',\n",
       " '”',\n",
       " ' ',\n",
       " '比赛',\n",
       " '结束',\n",
       " '后',\n",
       " ',',\n",
       " '同样',\n",
       " '来自',\n",
       " '德国',\n",
       " '的',\n",
       " '主教练',\n",
       " '蒂纳',\n",
       " '与',\n",
       " '波',\n",
       " '勒斯',\n",
       " '的',\n",
       " '态度',\n",
       " '截然',\n",
       " '相反',\n",
       " ',',\n",
       " '蒂纳',\n",
       " '的',\n",
       " '沮丧',\n",
       " '让',\n",
       " '人们',\n",
       " '看到',\n",
       " '了',\n",
       " '她',\n",
       " '对',\n",
       " '本场',\n",
       " '比赛',\n",
       " '的',\n",
       " '重视',\n",
       " ',',\n",
       " '而波',\n",
       " '勒斯',\n",
       " '则',\n",
       " '信誓旦旦',\n",
       " ',',\n",
       " '放出',\n",
       " '话',\n",
       " '来',\n",
       " ',',\n",
       " '德国',\n",
       " '将',\n",
       " '是',\n",
       " '世界',\n",
       " '第一',\n",
       " '。',\n",
       " '曾经',\n",
       " '0',\n",
       " '比',\n",
       " '8',\n",
       " '惨败',\n",
       " '给',\n",
       " '德国',\n",
       " '后',\n",
       " ',',\n",
       " '中国女足',\n",
       " '进入',\n",
       " '了',\n",
       " '一个',\n",
       " '变革',\n",
       " '时期',\n",
       " '。',\n",
       " '中国女足',\n",
       " '再也',\n",
       " '不是',\n",
       " '世界',\n",
       " '的',\n",
       " '霸主',\n",
       " ',',\n",
       " '甚至',\n",
       " '在',\n",
       " '亚洲',\n",
       " '也',\n",
       " '难保',\n",
       " '第一',\n",
       " '。',\n",
       " '一连串',\n",
       " '的',\n",
       " '溃败',\n",
       " '也',\n",
       " '让',\n",
       " '世界',\n",
       " '强队',\n",
       " '把',\n",
       " '中国队',\n",
       " '排出',\n",
       " '在',\n",
       " '竞争对手',\n",
       " '之',\n",
       " '列',\n",
       " '。',\n",
       " ' ',\n",
       " '波',\n",
       " '勒斯',\n",
       " '的',\n",
       " '叫板',\n",
       " '也',\n",
       " '就',\n",
       " '显得',\n",
       " '自然',\n",
       " ',',\n",
       " '中国女足',\n",
       " '能否',\n",
       " '通过',\n",
       " '本场',\n",
       " '比赛',\n",
       " '重拾',\n",
       " '信心',\n",
       " ',',\n",
       " '世界杯',\n",
       " '前',\n",
       " '还有',\n",
       " '很多',\n",
       " '路要',\n",
       " '走',\n",
       " '。',\n",
       " ' ',\n",
       " '(',\n",
       " '责任编辑',\n",
       " ':',\n",
       " 'liumiaoyao',\n",
       " ')',\n",
       " ' ',\n",
       " 'Copyright',\n",
       " ' ',\n",
       " 'c',\n",
       " ' ',\n",
       " '2007',\n",
       " ' ',\n",
       " 'Sohu',\n",
       " '.',\n",
       " 'com',\n",
       " ' ',\n",
       " 'Inc',\n",
       " '.',\n",
       " ' ',\n",
       " 'All',\n",
       " ' ',\n",
       " 'rights',\n",
       " ' ',\n",
       " 'reserved',\n",
       " '.',\n",
       " ' ',\n",
       " '搜狐公司',\n",
       " ' ',\n",
       " '\\n']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_s[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '搜狐', '体育讯', ' ', '雪藏', '杰拉德', '的', '利物浦', '(', '利物浦', '新闻', ',', '利物浦', '说', '吧', ')', '坐镇', '主场', '兵不血刃', '地', '击败', '维冈', '竞技', ',', '荷兰', '射手', '库', '伊特', '无疑', '是', '头号', '功臣', '。', '他', '在', '本场', '比赛', '中', '两个', '精彩', '的', '进球', '为', '球队', '带来', '了', '三分', '。', '值得一提的是', '荷兰人', '上周三', '刚刚', '喜', '得', '贵子', ',', '而', '上帝', '历来', '总是', '喜欢', '给', '这些', '父亲', '们', '一些', '小', '礼物', ',', '比如', '进球', '。', '这次', '礼物', '来', '了', '两分', ',', '球队', '也', '轻松', '取胜', ',', '着实', '可喜可贺', '。', '—', '—', '祝贺', '库', '伊特', '双喜临门', ' ', '由于', '贝拉', '米', '刚刚', '痊愈', '不久', ',', '库', '伊特', '今天', '继续', '与', '克劳奇', '组成', '双高', '组合', '。', ' ', '而', '比赛', '中', '荷兰人', '继续', '着', '自己', '位置', '灵活', '跑动', '积极', '的', '特点', ',', '与', '高佬', '的', '配合', '十分', '默契', '。', '这样', '的', '扯动', '也', '让', '身边', '的', '彭', '南特', '、', '马克', '.', '冈萨雷斯', '等', '人', '有', '了', '更', '多', '的', '自由发挥', '空间', ',', '红军', '闲庭信步', '般', '控制', '着', '节奏', ',', '体现', '着', '他们', '高出', '对手', '两个', '档次', '以上', '的', '实力', '。', '—', '—', '您', '认为', '红军', '三大', '前锋', '谁', '最强', '?', ' ', '而库', '伊特', '终于', '是', '在', '第', '30', '分钟', '利用', '换位', '到', '左路', '的', '彭', '南特', '精准', '的', '传中', ',', '将球', '狠狠', '顶进', '大门', '。', '这个', '进球', '带来', '的', '1', '-', '0', '领先', '足以', '宣判', '客队', '的', '死刑', ',', '疲于', '防守', '的', '他们', '尽管', '排出', '5', '名', '中场', ',', '却', '依然', '无法', '与', '利物浦', '在', '全', '欧洲', '最有', '统治力', '的', '中场', '抗衡', ',', '即使', '他们', '三名', '世界级', '的', '中', '前卫', ':', '杰拉德', '、', '马斯切', '拉诺', '和', '西索科', '都', '没有', '出场', '。', '这样', '他们', '根本无法', '打出', '有效', '反击', ',', '上半场', '比赛', '居然', '一脚', '射门', '没有', ',', '难怪', '库', '伊特', '为首', '的', '红军', '攻击线', '在', '比赛', '中', '能够', '如此', '在', '客队', '禁区', '内', '肆意', '漫步', '。', ' ', '而', '下半场', '比赛', '中', ',', '利物浦', '有条不紊', '地', '继续', '对', '对手', '实行', '地毯式', '轰炸', ',', '荷兰', '前锋', '也', '继续', '着', '自己', '抢眼', '的', '表现', ',', '他', '的', '第二个', '进球', '本来', '应该', '在', '第', '64', '分钟', '就', '到来', ',', '但', '这次', '他', '亲自', '策划', '的', '进攻', '最后', '来自', '他', '自己', '和', '阿隆索', '(', '阿隆索', '新闻', ',', '阿隆索', '说', '吧', ')', '连续', '两脚', '射门', '都', '被', '挡', '出', ',', '着实', '缺乏', '一些', '运气', '。', '而', '在', '贝拉', '米', '出场', '后', ',', '迎回', '最', '熟悉', '搭档', '的', '库', '伊特', '更加', '自由', '。', '威尔士', '人', '第一次', '策划', '的', '进攻', '最终', '被', '门前', '嗅觉', '敏锐', '的', '库', '伊特', '将球', '打进', ',', '2', '-', '0', '。', ' ', '维冈人', '也', '被', '彻底', '击溃', ',', '随时', '等待', '比赛', '结束', '哨音响', '起', '的', '他们', '只能', '接着', '看着', '红军', '们', '的', '表演', '。', '之后', '最', '不留情面', '的', '还是', '库', '伊特', ',', '他', '有', '多次', '机会', '帮助', '球队', '将', '比分', '继续', '扩大', ',', '不过', '智利', '边锋', '马克', '.', '冈萨雷斯', '挥霍', '了', '他', '的', '传中', ',', '他', '自己', '也', '在', '补时', '阶段', '浪费', '了', '里瑟', '的', '传中', ',', '原本', '再', '完美', '不过', '的', '一个', '帽子戏法', '就', '这么', '没有', '了', '。', '不过', '考虑', '到', '9', '天前', '荷兰人', '家中', '新', '出世', '的', '大', '胖小子', '是', '库', '伊特', '第二个', '孩子', ',', '两个', '进球', '倒', '可以', '说', '是', '更', '有', '纪念', '意义', '。', ' ', '目前', '库', '伊特', '已经', '在', '联赛', '中为', '利物浦', '打进', '了', '12', '个', '进球', ',', '是', '红军', '的', '联赛', '头号', '射手', ',', '克劳奇', '的', '9', '球', '和', '杰拉德', '的', '7', '球', '都', '无法', '超过', '荷兰人', '。', '不过', '值得一提的是', ',', '库', '伊特', '本赛季', '在', '其他', '赛事', '中', '进球', '率', '十分', '不', '理想', ',', '只是', '在', '足总杯', '打进', '一球', ',', '欧冠', '和', '联赛', '杯', '都', '是', '一球', '没进', '。', '高佬', '克劳奇', '联赛', '尽管', '“', '只', '”', '进', '9', '球', ',', '但', '在', '欧洲', '冠军联赛', '的', '7', '个', '进球', '个个', '精彩', ',', '也', '成为', '了', '球迷', '心中', '的', '超级', '英雄', '。', '库', '伊特', '几天', '后', '在', '对阵', '切尔西', '(', '切尔西', '新闻', ',', '切尔西', '说', '吧', ')', '的', '比赛', '中', '如果', '能够', '持续', '自己', '的', '进球', '运', ',', '不仅', '能够', '帮助', '球队', ',', '也', '能', '让', '自己', '打破', '本赛季', '尴尬', '的', '欧冠', '“', '零蛋', '”', '成绩单', '。', '—', '—', '您', '认为', '库', '伊特', '能', '迎来', '自己', '的', '首个', '欧冠', '进球', '吗', '?', ' ', '(', '罗萨里奥', ')', ' ', '(', '责任编辑', ':', 'harbuzi', ')', ' ', '\\n']\n"
     ]
    }
   ],
   "source": [
    "df_content=pd.DataFrame({'content_s':content_s})#将列表转换成字典,再写成二维格式\n",
    "df_content.head()\n",
    "#contents=df_content.content_s.values.tolist()\n",
    "#print(contents[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>责任编辑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>liumiaoyao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Copyright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stopword\n",
       "0          \\n\n",
       "1        责任编辑\n",
       "2  liumiaoyao\n",
       "3   Copyright\n",
       "4        2007"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=pd.read_csv('stopwords.txt',index_col=False,quoting=3,names=['stopword'])\n",
    "stopwords.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'content_s'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-bc0873a2dbc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#print(contents_clean)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcontents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_content\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'content_s'"
     ]
    }
   ],
   "source": [
    "\n",
    "def drop_stopwords(contents,stopwords):\n",
    "    contents_clean=[]\n",
    "    all_words=[]\n",
    "    for line in contents:\n",
    "        line_clean=[]\n",
    "        for word in line:\n",
    "            if word not in stopwords:\n",
    "                continue\n",
    "            line_clean.append(word)\n",
    "            all_words.append(str(word))#准备做词云\n",
    "        contents_clean.append(line_clean)\n",
    "        return contents_clean,all_words\n",
    "        #print(contents_clean)\n",
    "        \n",
    "contents=df_content.content_s.values.tolist()\n",
    "stopwords=stopwords.stopword.values.tolist()\n",
    "contents_clean,all_words=drop_stopwords(contents,stopwords)\n",
    "#df_content.content_s.isin(stopwords.stopword)\n",
    "#df_content=df_content[df_content.content_s.isin(stopwords.stopwrd)]\n",
    "#df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\\n, 新华网, 武汉, 月, 21, 日电, 记者, 郑道, 锦,  , 李鹏, 翔, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      contents_clean\n",
       "0  [\\n, 新华网, 武汉, 月, 21, 日电, 记者, 郑道, 锦,  , 李鹏, 翔, ..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content=pd.DataFrame({'contents_clean':contents_clean})\n",
    "df_content.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>新华网</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>武汉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>月</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_words\n",
       "0        \\n\n",
       "1       新华网\n",
       "2        武汉\n",
       "3         月\n",
       "4        21"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_words=pd.DataFrame({'all_words':all_words})\n",
    "df_all_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "words_count=df_all_words.groupby(by=['all_words'])['all_words'].agg({'count':numpy.size})\n",
    "words_count=words_count.reset_index().sort_values(by=['count'],assending=False)\n",
    "words_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize']=(10.0,5.0)\n",
    "wordcloud=WordCloud(font_path='/data/simhei.ttf',background_color='white',max_front_size=80)\n",
    "word_frequence={x[0]:x[1] for x in words_count.head(100).values}\n",
    "wordcloud=wordcloud.fit_words(word_frequence)\n",
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tTF-IDF提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analise\n",
    "index = 100\n",
    "ptint(df['content'][index])\n",
    "content_S_str=''.join(content_s[index])\n",
    "print(' '.join(jieba.analyse.extract_tags(content_S_str,topK=5,withWeght=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA主题模型\n",
    "格式要求：list of list形式，分词好的的珍格格语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora,models,similarities\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#做映射，相当于词袋\n",
    "dictionary=corpora.Dictionary(contents_clean)\n",
    "corpus=[dictionary.doc2bow(setence) for setence in contents_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=dictionary,num_topics=20)#类似Kmeans自己指定K的值，分多少块，即确定几个主题关键字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一号分类结果\n",
    "print(lda.print_topic(1,topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in lda.print_topics(num_topics=20,num_words=5):\n",
    "    print(topic[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运用朴素贝叶斯进行模型检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame({'contents_clean':contents_clean,'label':df['label']})\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping={'汽车':1,'财经':2,'科技':3}\n",
    "df_train['label']=df_train['label'].map(label_mapping)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df_train['contents_clean'].values,df_train['label'].values,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train=x_train.flatten()\n",
    "x_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for line_index in range(len(x_train)):\n",
    "    try:\n",
    "        #x_train[line_index][word_index]=str(x_train[line_inde][word_index])\n",
    "        words.append(' '.join(x_train[line_index]))#把list转换成字符串\n",
    "        except:\n",
    "            print(line_index,word_index)\n",
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#构建Ngram词袋模型#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird', 'cat', 'dog', 'fish']\n",
      "[[0 1 1 1]\n",
      " [0 2 1 0]\n",
      " [1 0 0 1]\n",
      " [1 0 0 0]]\n",
      "[2 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts=['dog cat fish','dog cat cat','fish bird','bird']\n",
    "cv=CountVectorizer()\n",
    "cv_fit=cv.fit_transform(texts)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print(cv_fit.toarray())\n",
    "\n",
    "print(cv_fit.toarray().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird', 'cat', 'cat cat', 'cat fish', 'dog', 'dog cat', 'dog cat cat', 'dog cat fish', 'fish', 'fish bird']\n",
      "[[0 1 0 1 1 1 0 1 1 0]\n",
      " [0 2 1 0 1 1 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0]]\n",
      "[2 3 1 1 2 2 1 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts=['dog cat fish','dog cat cat','fish bird','bird']\n",
    "cv=CountVectorizer(ngram_range=(1,4))\n",
    "cv_fit=cv.fit_transform(texts)\n",
    "\n",
    "print(cv.get_feature_names())\n",
    "print(cv_fit.toarray())\n",
    "\n",
    "print(cv_fit.toarray().sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec=CountVectorizer(analyzer='word',max_faetures=4000,lowercase=False)\n",
    "vec.fit(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "贝叶斯出来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier=MultinomialNB()\n",
    "classifier.fit(vec.transform(words),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words=[]\n",
    "for line_index in range(len(x_test)): #x_test为测试集\n",
    "    try:\n",
    "        #x_train[line_index][word_index]=str(x_train[line_index][word_index])\n",
    "        test_words.append(' '.join(x_test[line_index]))\n",
    "    except:\n",
    "        print(line_index,word_index)\n",
    "test_words[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(vec.transform(test_words),y_test)#基于词频的向量构造，基本叶贝丝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "再进行ifidf构造向量，精确度看下面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text omport TfidfVectorizer\n",
    "vectorizer=TfidfVectorizer(analyzer='word',max_features=4000,lowercase=False)\n",
    "vectorizer.fit(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.native_bayes import MultinomialNB\n",
    "classifier=<ultinomialNB()\n",
    "classifier.fit(vectorizer.transform(words),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(vec.transform(test_words),y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
